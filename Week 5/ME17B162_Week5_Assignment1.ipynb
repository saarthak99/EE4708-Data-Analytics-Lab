{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saarthak Marathe | ME17B162 \n",
    "# Classification : Nearest Neighbors and Naive Bayes "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification using Nearest Neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(a) Perform k-Nearest neighbours on the given dataset($X_{knn}$ and $y_{knn}$: where $X_{knn}$ stores feature vectors representing the movies and  $y_{knn}$ stores the 0-1 labelling for each movie) for binary classification of movies, for classifiying whether a given movie is a comedy(label 1) or not a comedy(label 0) . Split the dataset into train(80%), validation(10%) and test sets(10%).Run k-Nearest neighbours for different k values (1,3,7,15,31,63). Select the k, using validation set, which returns the best accuracy score. \n",
    "\n",
    "(i)  Report all the validation accuracies for all the values of k. \n",
    "<br>(ii) Report accuracy score by performing k-NN on the test dataset using the best chosen k value. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## write your code here.\n",
    "import pandas as pd\n",
    "x_knn = pd.read_csv('X_knn.csv', header = None)\n",
    "y_knn = pd.read_csv('y_knn.csv', header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [0]*len(x_knn)\n",
    "for i in range(len(x_knn)):\n",
    "    x[i] = [float(x) for x in x_knn[0][i].split()] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = [0]*len(y_knn)\n",
    "for i in range(len(x_knn)):\n",
    "    y[i] = y_knn[0][i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x1, x_test, y1, y_test = train_test_split(x, y, test_size=0.10)\n",
    "x_train, x_val, y_train, y_val = train_test_split(x1, y1, test_size=0.111)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(x_train)\n",
    "\n",
    "x_train = scaler.transform(x_train)\n",
    "x_val = scaler.transform(x_val)\n",
    "x_test = scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1eb8d48bd90>]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD4CAYAAADiry33AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAek0lEQVR4nO3deXhV9b3v8feXhASSMGUTBBmECIKIAjYy1A7OhWorp8MR+njbp+2ttbdetB7b6nE6VW+Pbe2grbeUU9ueczyVWlsVlYpD1V570BJlkDCGCBKmBCIzmb/3j70DuyGQHUiy9l7r83oeHvZee+21vz+GD4vvXuv3M3dHRETCq0fQBYiISNdS0IuIhJyCXkQk5BT0IiIhp6AXEQm57KALaMvAgQN95MiRQZchIpIx3nrrrV3uXtTWa2kZ9CNHjqS0tDToMkREMoaZbT7ea2rdiIiEnIJeRCTkFPQiIiGnoBcRCTkFvYhIyCnoRURCTkEvIhJyoQl6d+enL2/gtfXVQZciIpJWQhP0Zsb8v1TwytqqoEsREUkroQl6gMKCHHYfrA+6DBGRtBKuoM/PoeZgXdBliIiklVAFfSw/h90HdEYvIpIsVEEfP6NX0IuIJAtZ0Ofy/qF6tOC5iMhRoQr6WH4ODU3OvtrGoEsREUkboQr6wvwcALVvRESShCvoC1qCXlfeiIi0CFXQxxJn9LryRkTkqHAFfUEuoNaNiEiycAV9yxm9gl5E5IhQBX2vnlnk5WTpjF5EJEmogh5005SISGuhC/pYviY2ExFJllLQm9kMM1tnZuVmdmsbr48zsyVmVmdmt7R67RtmVmZmq8zsMTPr1VnFt6UwP4fdB3R5pYhIi3aD3syygIeBmcB4YI6ZjW+1Ww0wF3ig1XuHJraXuPsEIAuY3Ql1H1dhfq5aNyIiSVI5o58ClLt7hbvXAwuAq5N3cPcqd18KNLTx/mygt5llA3nAtlOs+YRiiTnpNd+NiEhcKkE/FNiS9Lwysa1d7r6V+Fn+e8B2YK+7v9DWvmZ2nZmVmllpdfXJLwdYmJ9DfWMzB+ubTvoYIiJhkkrQWxvbUjpdNrMBxM/+RwGnA/lmdm1b+7r7fHcvcfeSoqKiVA7fpiPz3ejuWBERILWgrwSGJz0fRurtl8uAd9292t0bgD8CH+xYiR1z9KYpfSErIgKpBf1SYIyZjTKzHOJfpi5M8fjvAdPMLM/MDLgUWHNypaZGM1iKiPy97PZ2cPdGM7sBWEz8qplfuXuZmV2feH2emQ0GSoG+QLOZ3QSMd/c3zewJ4G2gEVgGzO+isQAQy4/Pd6Nr6UVE4toNegB3XwQsarVtXtLjHcRbOm29927g7lOosUOOTlWsoBcRgRDeGZufk0Vudg8FvYhIQuiC3szi0yDoqhsRESCEQQ/x9o1WmRIRiQtn0GsaBBGRI0IZ9JrBUkTkqFAGfaF69CIiR4Q26A83NHFY892IiIQz6DUNgojIUaEMek2DICJyVCiDPlbQckavoBcRCWXQFybmu9FUxSIioQ16tW5ERFqEMuj79sqmZ5apdSMiQkiD3swYkKdpEEREIKRBDxAr0DQIIiIQ5qDXNAgiIkCIg74wP0dn9CIihD3odXmliEh4gz6Wn8P+ukbqGjXfjYhEW2iDXmvHiojEhTboj0xspvaNiERcaIP+yDQIOqMXkYgLcdCrdSMiAiEO+qNz0ivoRSTaQhv0/Xr3JKuHaRoEEYm8lILezGaY2TozKzezW9t4fZyZLTGzOjO7JWn7WDNbnvRjn5nd1JkDOJ4ePYwBeT3VuhGRyMtubwczywIeBi4HKoGlZrbQ3Vcn7VYDzAVmJb/X3dcBk5KOsxV4snNKb58WCRcRSe2MfgpQ7u4V7l4PLACuTt7B3avcfSnQcILjXApsdPfNJ11tB2kaBBGR1IJ+KLAl6XllYltHzQYeO96LZnadmZWaWWl1dfVJHP5YsXzNYCkikkrQWxvbvCMfYmY5wCeB3x9vH3ef7+4l7l5SVFTUkcMfV6xAM1iKiKQS9JXA8KTnw4BtHfycmcDb7r6zg+87JYX5Oew93EBDU3N3fqyISFpJJeiXAmPMbFTizHw2sLCDnzOHE7RtukrLtfTvH9JZvYhEV7tX3bh7o5ndACwGsoBfuXuZmV2feH2emQ0GSoG+QHPiEsrx7r7PzPKIX7Hz1S4bxXEkT4MwqE+v7v54EZG00G7QA7j7ImBRq23zkh7vIN7Saeu9h4DYKdR40go1sZmISHjvjIX4l7GgaRBEJNpCHfRHJjY7oGkQRCS6Qh30A/JyMNMMliISbaEO+qweRv/ePdW6EZFIC3XQg6ZBEBEJfdDH8nN1Ri8ikRb6oNcZvYhEXfiDvkBBLyLRFvqgj+Xn8P6hepqaOzQPm4hIaEQi6N1hj+a7EZGICn3QFxYcne9GRCSKQh/0LTNY6sobEYmq0Af9kWkQFPQiElGhD/ojZ/Sa70ZEIir0QT9ArRsRibjQB33PrB707ZWt1o2IRFbogx4gVqBpEEQkuiIR9IX5OdRolSkRiajoBL3O6EUkoiIR9LH8HLVuRCSyIhH0hYn5bpo1342IRFBkgr6p2dlX2xB0KSIi3S4SQR8r0LX0IhJd0Qj6fE1sJiLRFYmgLzwyDYKCXkSiJ6WgN7MZZrbOzMrN7NY2Xh9nZkvMrM7Mbmn1Wn8ze8LM1prZGjOb3lnFp6qldaMzehGJouz2djCzLOBh4HKgElhqZgvdfXXSbjXAXGBWG4d4EHje3T9jZjlA3qmX3TFHZ7DUxGYiEj2pnNFPAcrdvcLd64EFwNXJO7h7lbsvBf7ushYz6wt8BHgksV+9u+/plMo7IDc7i4LcbHapdSMiEZRK0A8FtiQ9r0xsS0UxUA382syWmdkvzSy/rR3N7DozKzWz0urq6hQPnzrdHSsiUZVK0Fsb21K98ygbOB/4ubtPBg4Cx/T4Adx9vruXuHtJUVFRiodPnYJeRKIqlaCvBIYnPR8GbEvx+JVApbu/mXj+BPHg73aaBkFEoiqVoF8KjDGzUYkvU2cDC1M5uLvvALaY2djEpkuB1Sd4S5eJn9Hry1gRiZ52r7px90YzuwFYDGQBv3L3MjO7PvH6PDMbDJQCfYFmM7sJGO/u+4D/DfxX4h+JCuCLXTSWEyosiLdu3B2ztrpRIiLh1G7QA7j7ImBRq23zkh7vIN7Saeu9y4GSU6ixU8Tyc2hocvbXNdK3V8+gyxER6TaRuDMWoLBlGgRdYikiEROZoI9pkXARiaiUWjdhcPTuWAW9tK+52dlzWNNaS/cyYEAiqzpTBINeV97Iif21fBd3Pr2KiuqDQZciETOwIJfSOy7r9ONGJug1J720Z+e+Wu57bg3PrNjGiMI87rjybHpmRaa7KWmgd8+sLjluZII+Lyeb3j2z9GWsHKOxqZl/X7KZH7+4nvqmZm68dAxfu+hMenXRXzqR7haZoAdNgyDHemtzDbc/uYq1O/bz0bOK+M4nz2HkwDanYxLJWJEK+lhBDrsU9EL8S/n7/7SGx0srGdKvF/OuPZ+PnTNYN9NJKEUq6Avzc9h1QF/GRllzs7Ng6Ra+v3gtB2ob+epHipl76RjycyP1V0EiJlJ/ugvzc1i/Y3/QZUhAVm3dy+1PrWLFlj1MHVXIvbMmcNZpfYIuS6TLRSroW2aw1Hw30bL3cAM/fGEdj76xmcL8XH58zURmTRqqPwMSGZEK+sL8XOoamzlU36T/qkeAu/PU8q38n+fWUHOwnv8x7QxuvmIs/XprriOJlkilXSzp7lgFfbit37mfO59axZvv1jBxeH9+88UpTBjaL+iyRAIRqbQrTJrvZnhht69RLt3gYF0jD728gUdef5f83Gy++w/nMvuC4fTooTaNRFe0gr5A0yCElbvz/Kod3PPsarbvreUfS4bx7RnjiBXkBl2aSOAiFfRHZrDU3bGhsmnXQe5eWMZr66sZN7gPP/vcZD5wRmHQZYmkjUgFvWawDJfahiZ+/upGfv7aRnKyenDXVeP5/PQzyNb8NCJ/J1JBX5CbTU5WDwV9CLyyroq7ny7jvZpDfHLi6dx+5dmc1rdX0GWJpKVIBb2ZESvI0QyWGWzrnsPc80wZi8t2UlyUz2//51Q+OHpg0GWJpLVIBT1oYrNMVd/YzCOvv8tDL2/Acb75sbF85cPF5GSrTSPSnkgGvc7oM8uSjbu58+lVlFcd4PLxp3HXVeN1eaxIB0Qu6GP5Oby7SysHZYKq/bV897k1PLV8G8MG9OaRL5Rw6dmnBV2WSMaJXNAX5ueqdZPmGpuaefSNzfzwhfXUNTYz95LR/K+LR2shEJGTFLmgjxXkcKi+idqGJgVHGnr7vfe548lVrN6+jw+PGcg9V09glBYCETklkQv65GkQhvbvHXA10uL9g/V87/m1LFi6hcF9e/Hw587n4+dqIRCRzpBS0JvZDOBBIAv4pbvf3+r1ccCvgfOB2939gaTXNgH7gSag0d1LOqf0k3PkpqkDCvp00NzsPF66he89v5Z9tY185cOjuPGysyjQpHMinabdv01mlgU8DFwOVAJLzWyhu69O2q0GmAvMOs5hLnb3XadabGc4Mg2C5rsJXNm2vdzx1CqWvbeHC0YO4N5ZExg3uG/QZYmETiqnTVOAcnevADCzBcDVwJGgd/cqoMrMruySKjtRUZ/4JFfb99YGXEl07att4EcvrOc/lmxiQF4OP/zsRD51vhYCEekqqQT9UGBL0vNKYGoHPsOBF8zMgV+4+/y2djKz64DrAEaMGNGBw3fM8AF5FObnsHRTDXOmdN3nyLHcnYUrtnHfc2vYdaCOa6eewS1XjKVfnhYCEelKqQR9W6dZ3oHPuNDdt5nZIOBFM1vr7n855oDxfwDmA5SUlHTk+B3So4cxdVQhb1bUaEnBblRetZ87nypjScVuJg7rxyNfKOG8Yf2DLkskElIJ+kpgeNLzYcC2VD/A3bclfq4ysyeJt4KOCfruNK04xp9W7aDy/cO6w7KLHapv5KGXy3nk9Qp698zivlkTmDNlBFlaCESk26QS9EuBMWY2CtgKzAY+l8rBzSwf6OHu+xOPrwDuOdliO8u04hgASyp2K+i7iLvzwuqd3PPMarbuOcxnPjCMW2eOY6AWAhHpdu0Gvbs3mtkNwGLil1f+yt3LzOz6xOvzzGwwUAr0BZrN7CZgPDAQeDLRHskGfuvuz3fNUFJ31mkFFObn8EbFbv6xZHj7b5AOeW/3Ie5euIpX1sUXAvn99dO5YKQWAhEJSkoXK7v7ImBRq23zkh7vIN7SaW0fMPFUCuwKZsa0YvXpO1ttQxO/eK2C//tqOdk9jDuuPJsvfHAkPbUQiEigIntXyrTiGIveUZ++s7y2vpq7n17Fpt2HuOq8Idxx5XgG99NCICLpINJBD/EpcBX0J2/73sPc++xqFr2zg+KB+Tz65al8aIwWAhFJJ5EN+jGDkvr0F6hP31ENTc38+q/v8pOXNtDU7NxyxVl85SPF5GZrojiRdBPZoG/p079RsVt9+g56syK+EMj6nQe47OxB3P2Jc/S/IpE0Ftmgh6N9+i01hxkRU1C1p3p/Hf+6aA1/XLaVof1782+fL+Hy8VoIRCTdRT7oAd6o2K2gP4GmZue3b27m+4vXUdvQxNcvPpMbLh5D7xy1aUQyQaSDfsygAmLq05/Q8i17uPOpVbyzdS8Xjo5xz9UTOLOoIOiyRKQDIh308T59TH36Nuw5VM/3F6/jsb+9R1FBLj+dM5mrzhuiXyORDBTpoAeYVlzIc+9sV58+obnZeeLtSu7/01r2Hm7gSxeO4qbLxtCnl2aYFMlUCnr16Y9Ys30fdz61itLN71NyRnwhkLOHaCEQkUwX+aAfnejTL4lwn35/bQM/eWkDv/nvTfTr3ZMffOY8Pn3+MHpohkmRUIh80Ee5T+/uPLtyO/c+u5rqA3XMmTKCb31sLP3zcoIuTUQ6UeSDHo726d+rOcQZsfygy+kWG6sPcPfTZbxevosJQ/sy//MlTBquhUBEwkhBD0w/82ifPuxBf7i+iZ+9soH5f6mgV88s7r36HD439QwtBCISYgp64MyiAgYW5PBGRQ3XXBDedWRfXL2Tf1lYxtY9h/nU+UO5bebZRxZLF5HwUtAT79NPDXGffkvNIb7zTBkvranirNMK+N1105iauNpIRMJPQZ8wrTjGcyvD1advanbmvbaRh17eQFYP458/Po4vXjhKC4GIRIyCPmF6cXypuzD16R9+pZwfvbiemRMGc9cnxjOkX++gSxKRAOjULqGlT79k4+6gS+kUb22u4cGXNzBr0un8/NoPKORFIkxBn3C0Tx9fRzaT7attYO5jyzm9fy/unTUh6HJEJGAK+iTTimPs2FfL5t2Hgi7lpLk7tz+5ih37anlw9mTNUSMiCvpk05PmvclUf3h7K8+s2MY3LhvD+SMGBF2OiKQBBX2SM4vyGViQm7FBv2nXQe56ehVTRxXytYtGB12OiKQJBX2So+vIZl6fvr6xmbkLltEzqwc/vmaS7nQVkSMU9K1kap/+Ry+uZ2XlXu7/1Lmc3l9X2IjIUSkFvZnNMLN1ZlZuZre28fo4M1tiZnVmdksbr2eZ2TIze7Yziu5K0zKwT//X8l384i8bmTNlODPPHRJ0OSKSZtoNejPLAh4GZgLjgTlmNr7VbjXAXOCB4xzmRmDNKdTZbVr69EsyJOhrDtbzjd8tp3hgPnde1fq3RUQktTP6KUC5u1e4ez2wALg6eQd3r3L3pUBD6zeb2TDgSuCXnVBvlzvap9+d9n16d+dbT6xkz6EGHpozmbwc3egsIsdKJeiHAluSnlcmtqXqJ8C3gOYT7WRm15lZqZmVVldXd+DwnW9acYyd++rYlOZ9+kfffI+X1uzk2zPHcc7p/YIuR0TSVCpB39blGymd6prZVUCVu7/V3r7uPt/dS9y9pKioKJXDd5nk+enT1bod+7nv2dV89KwivvjBkUGXIyJpLJWgrwSSF1MdBmxL8fgXAp80s03EWz6XmNmjHaowAMUD8ynqk77X09c2NDH3sWX06ZXNA5+dqLVdReSEUgn6pcAYMxtlZjnAbGBhKgd399vcfZi7j0y878/ufu1JV9tNWq8jm27u/9Na1u3czwOfnaiFQ0SkXe0Gvbs3AjcAi4lfOfO4u5eZ2fVmdj2AmQ02s0rgZuAOM6s0s75dWXhXm1ZcmJZ9+pfX7OQ3/72JL104iovGDgq6HBHJACldpuHui4BFrbbNS3q8g3hL50THeBV4tcMVBiT5evpRA9NjfvqqfbV884mVnD2kL9+eOTbockQkQ+jO2ONo6dOny/z0zc3OzY+v4FB9Iz+dM4nc7KygSxKRDKGgP45069P/8vUKXi/fxV1XncPoQX2CLkdEMoiC/gSmF8eo2l/Hu7sOBlrHO5V7+cHidcw4ZzBzpgxv/w0iIkkU9Ccw7cg6sjWB1XCwrpG5C5YRy8/l/k+fi5kupRSRjlHQn8CogfkMCvh6+u88U8am3Qf58TWT6J+XE1gdIpK5FPQnEHSf/tmV23i8tJKvXzT6yN26IiIdpaBvx7SA+vSV7x/itj++w6Th/bnxsjHd+tkiEi4K+nYE0advbGrmpgXLcYeHZk+mZ5Z+m0Tk5ClB2hFEn/5nr5RTuvl97ps1gRGxvG77XBEJJwV9O1r69Eu6qU9fuqmGh17ewD9MHsqsyR2ZDVpEpG0K+hRMPzNG9f46Krq4T7/3cAM3LljOsAF53HP1OV36WSISHQr6FHTHOrLuzu1PvsOOfbU8OHsSfXr17LLPEpFoUdCnYGQsj9P65nbpF7JPvFXJsyu3c/PlZzF5xIAu+xwRiR4FfQq6+nr6d3cd5O6FZUwrLuT6j57Z6ccXkWhT0KdoWnHX9OnrG5uZ+9gyemb14MfXTCJLq0WJSCdT0Keoq/r0P3xxHe9s3cv3Pn0eQ/r17tRji4iAgj5lXdGnf33DLn7xWgWfmzqCGRMGd9pxRUSSKehTdOR6+o2d06fffaCOmx9fzuhBBdx55fhOqFBEpG0K+g6YXhxj14E6NlafWp/e3fn2H1ay51ADD82eTO8crRYlIl1HQd8BndWn/883NvPSmipunTmO8adn9BrqIpIBFPQdcEYsj8F9e51S0K/bsZ/7nlvDRWOL+OKFIzuvOBGR41DQd0C8T1/IGxU1J9Wnr21oYu5jy+jbqycPfHaiVosSkW6hoO+gaafQp//uojWs27mfBz57HgMLcrugOhGRYynoO+hk+/Qvrd7JfyzZzJc/NIqLxg7qitJERNqkoO+gk+nT79xXyzefWMH4IX351oyxXVidiMixUgp6M5thZuvMrNzMbm3j9XFmtsTM6szslqTtvczsb2a2wszKzOw7nVl8EMyM6WfGUu7TNzc7//T4Cg43NPHQnMnkZutSShHpXu0GvZllAQ8DM4HxwBwza32HTw0wF3ig1fY64BJ3nwhMAmaY2bRTrjpg04oLE336A+3u+2//r4LXy3dx9yfOYfSggm6oTkTk76VyRj8FKHf3CnevBxYAVyfv4O5V7r4UaGi13d29JQ17Jn50/TJNXaylT7+knekQVlbu4QeL1zFzwmBmXzC8O0oTETlGKkE/FNiS9LwysS0lZpZlZsuBKuBFd3/zOPtdZ2alZlZaXV2d6uEDMaIwjyH9TtynP1jXyNzHllHUJ5d//dS5upRSRAKTStC3lVApn5W7e5O7TwKGAVPMbMJx9pvv7iXuXlJUVJTq4QPRMu/NmyeYn/5fFpaxueYQP7lmEv3zcrq5QhGRo1IJ+kogue8wDNjW0Q9y9z3Aq8CMjr43HcX79PVt9umfWbGN379VyQ0Xj2Zqos0jIhKUVIJ+KTDGzEaZWQ4wG1iYysHNrMjM+ice9wYuA9aebLHp5Hh9+i01h/jnJ99h8oj+zL10TBCliYj8nXaD3t0bgRuAxcAa4HF3LzOz683segAzG2xmlcDNwB1mVmlmfYEhwCtmtpL4PxgvuvuzXTWY7tRWn76xqZlv/G457vDQ7Mn0zNJtCiISvOxUdnL3RcCiVtvmJT3eQbyl09pKYPKpFJiuzIzpxTH+sqEad8fM+Omfyynd/D4Pzp7E8MK8oEsUEQF0Z+wpic97U0951QGWbqrhp3/ewKcmD+XqSSlflCQi0uVSOqOXtrX06ReX7eCxv21h2IA87pnV5kVFIiKBUdCfguGFvTm9Xy9+9OJ6epjxxNc+SEGufklFJL2odXMKWq6nb3a4+YqzmDS8f9AliYgcQ6efp+hLHxrF0AG9+epHzgy6FBGRNinoT9GEof2YMLRf0GWIiByXWjciIiGnoBcRCTkFvYhIyCnoRURCTkEvIhJyCnoRkZBT0IuIhJyCXkQk5Ox4S+EFycyqgc0p7DoQ2NXF5XQ1jSE9aAzpQWM4eWe4e5vrsKZl0KfKzErdvSToOk6FxpAeNIb0oDF0DbVuRERCTkEvIhJymR7084MuoBNoDOlBY0gPGkMXyOgevYiItC/Tz+hFRKQdCnoRkZDLyKA3sxlmts7Mys3s1qDrSZWZ/crMqsxsVdK2QjN70cw2JH4eEGSNJ2Jmw83sFTNbY2ZlZnZjYnvGjAHAzHqZ2d/MbEViHN9JbM+0cWSZ2TIzezbxPKPqBzCzTWb2jpktN7PSxLaMGoeZ9TezJ8xsbeLvxvR0G0PGBb2ZZQEPAzOB8cAcMxsfbFUp+w0wo9W2W4GX3X0M8HLiebpqBP7J3c8GpgFfT/zaZ9IYAOqAS9x9IjAJmGFm08i8cdwIrEl6nmn1t7jY3SclXXueaeN4EHje3ccBE4n/nqTXGNw9o34A04HFSc9vA24Luq4O1D8SWJX0fB0wJPF4CLAu6Bo7MJangcszfAx5wNvA1EwaBzCMeIBcAjybqX+WgE3AwFbbMmYcQF/gXRIXtqTrGDLujB4YCmxJel6Z2JapTnP37QCJnwcFXE9KzGwkMBl4kwwcQ6LtsRyoAl5090wbx0+AbwHNSdsyqf4WDrxgZm+Z2XWJbZk0jmKgGvh1oo32SzPLJ83GkIlBb21s0zWi3cjMCoA/ADe5+76g6zkZ7t7k7pOInxlPMbMJQdeUKjO7Cqhy97eCrqUTXOju5xNvxX7dzD4SdEEdlA2cD/zc3ScDBwm6TdOGTAz6SmB40vNhwLaAaukMO81sCEDi56qA6zkhM+tJPOT/y93/mNicUWNI5u57gFeJf3eSKeO4EPikmW0CFgCXmNmjZE79R7j7tsTPVcCTwBQyaxyVQGXif4QATxAP/rQaQyYG/VJgjJmNMrMcYDawMOCaTsVC4AuJx18g3vdOS2ZmwCPAGnf/UdJLGTMGADMrMrP+ice9gcuAtWTIONz9Nncf5u4jif/5/7O7X0uG1N/CzPLNrE/LY+AKYBUZNA533wFsMbOxiU2XAqtJtzEE/WXGSX4B8nFgPbARuD3oejpQ92PAdqCB+JnAl4EY8S/VNiR+Lgy6zhPU/yHibbKVwPLEj49n0hgS4zgPWJYYxyrgrsT2jBpHouaLOPplbEbVT7y/vSLxo6zl73IGjmMSUJr48/QUMCDdxqApEEREQi4TWzciItIBCnoRkZBT0IuIhJyCXkQk5BT0IiIhp6AXEQk5Bb2ISMj9f1udKhK+LR8yAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "k = [1,3,7,15,31,63]\n",
    "error = []\n",
    "for i in range(len(k)):\n",
    "    classifier = KNeighborsClassifier(n_neighbors=k[i])\n",
    "    classifier.fit(x_train, y_train)\n",
    "    y_pred = classifier.predict(x_val)\n",
    "    error.append(np.mean(y_pred != y_val))\n",
    "plt.plot(k, error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k: 1.000000, Error: 0.185185\n",
      "k: 3.000000, Error: 0.150150\n",
      "k: 7.000000, Error: 0.127127\n",
      "k: 15.000000, Error: 0.143143\n",
      "k: 31.000000, Error: 0.157157\n",
      "k: 63.000000, Error: 0.157157\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(k)):\n",
    "    print('k: %f, Error: %f' %(k[i], error[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Write the results here**\n",
    "\n",
    "From the graph, it is evident that the highest accuracy (lowest error) is for k = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for the test data: 0.8109999999999999\n"
     ]
    }
   ],
   "source": [
    "#for test dataset\n",
    "classifier = KNeighborsClassifier(n_neighbors=7)\n",
    "classifier.fit(x_train, y_train)\n",
    "y_pred = classifier.predict(x_test)\n",
    "error = (np.mean(y_pred != y_test))\n",
    "print('Accuracy for the test data:', 1-error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(b) State why using an even value of k in k-NN should not be chosen**\n",
    "\n",
    "Odd values for k are chosen mainly to avoid any ties with class label scores (distance) during cluster classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Naive Bayes' classifier  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From Continuous Distribution of data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, the distribution of the data( $X$ represents the datapoints and $Y$ represents the 0-1 binary-class label; where 0 being the negative class and 1 being the positive class) is already known.\n",
    "<br>Consider the following one-dimensional(1-D) Gaussian distributions where means and variances are unknown. You need to estimate means($\\mu_-$: for negative class and  $\\mu_+$: for positive class) and variances ($\\sigma^{2}_{-}$: for negative class and $\\sigma^{2}_+$: for positive class) from the given data : \n",
    "<br> (1) Assume $X|Y_{Y=0} \\sim \\mathcal{N}(\\mu_- , \\sigma^{2}_-)$ \n",
    "<br>(2) Assume $X|Y_{Y=1} \\sim \\mathcal{N}(\\mu_+ , \\sigma^{2}_+)$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Generating artificial datasets in the next cell *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This cell is for generating datasets. Students should not change anything in this cell. \n",
    "## You can compare your mean and variance estimates by the actual ones used to generate these datasets\n",
    "\n",
    "import numpy as np\n",
    "X_pos = np.random.randn(1000,1)+np.array([[2.]])\n",
    "X_neg = np.random.randn(1000,1)+np.array([[4.]])\n",
    "X_train_pos = X_pos[:900]\n",
    "X_train_neg = X_neg[:900]\n",
    "X_test_pos = X_pos[900:]\n",
    "X_test_neg = X_neg[900:]\n",
    "X_train = np.concatenate((X_train_pos, X_train_neg), axis=0)\n",
    "X_test = np.concatenate((X_test_pos, X_test_neg), axis=0)\n",
    "Y_train = np.concatenate(( np.ones(900),np.zeros(900) ))\n",
    "Y_test = np.concatenate(( np.ones(100), np.zeros(100) ))\n",
    "\n",
    "## X_train, X_test, Y_train, Y_test are your datasets to work with ####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "<br>**Instructions to follow for learning a Baeysian classifier:** *(Code the formulae for estimating the different parameters yourself)*\n",
    "<br> a)Utilize the training dataset to estimate the means($\\hat{\\mu_+}$,$\\hat{\\mu_-}$) and variances($\\hat{\\sigma^{2}_+}$, $\\hat{\\sigma^{2}_-}$) for both positive and negative classes  \n",
    "b)Estimate the prior probability: $P(Y=1)$  ⟶ which could be referred to as: $\\hat{a}$ \n",
    "<br>c)Estimate the classifier funtion/posterior probability:  $P(Y=1|X = x)$  ⟶ which could be referred to as $\\hat{\\eta(x)}$\n",
    "<br>d)Find out the threshold value($x^*$) for classification by equating the estimated classifier function($\\hat{\\eta(x)}$)  with threshold probability of 0.5\n",
    "<br>e)Classify the test dataset into the two classes using this threshold value($x^*$) and find out the **accuracy** of the prediction \n",
    "\n",
    "Return back:  $\\hat{\\mu_+}$, $\\hat{\\mu_-}$, $\\hat{\\sigma^{2}_+}$, $\\hat{\\sigma^{2}_-}$, $\\hat{a}$, $x^*$ and accuracy from the code written \n",
    "\n",
    "*Hint: $X|Y_{Y=0} \\sim \\mathcal{N}(\\mu_- , \\sigma^{2}_-)$ implies $P_{X|Y=0} = \\mathcal{N}(\\mu_- , \\sigma^{2}_-) $*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "## write your code here.  \n",
    "\n",
    "#mean and variance for both the datas\n",
    "def mean(x):\n",
    "    sum = 0\n",
    "    for i in range(len(x)):\n",
    "        sum = sum + x[i]\n",
    "    return sum/len(x)\n",
    "\n",
    "def variance(x):\n",
    "    mu = mean(x)\n",
    "    var=0\n",
    "    for i in range(len(x)):\n",
    "        var = var + (((x[i] - mu)**2)/(len(x)-1))\n",
    "    return var\n",
    "mean_pos = mean(X_train_pos)\n",
    "mean_neg = mean(X_train_neg)\n",
    "var_pos = variance(X_train_pos)\n",
    "var_neg = variance(X_train_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prior probability\n",
    "ones = 0\n",
    "for i in range(len(Y_train)):\n",
    "    if Y_train[i] == 1:\n",
    "        ones = ones + 1\n",
    "ahat = ones/len(Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from scipy.stats import norm\n",
    "import math\n",
    "def muhat(x):\n",
    "    pdf_pos = (1/(var_pos*(math.sqrt(2*math.pi))))*(math.exp((-1/2)*(((x-mean_pos)/var_pos)**2)))\n",
    "    pdf_neg = (1/(var_neg*(math.sqrt(2*math.pi))))*(math.exp((-1/2)*(((x-mean_neg)/var_neg)**2)))\n",
    "    \n",
    "    return ahat*pdf_pos/(ahat*pdf_pos + ((1-ahat)*pdf_neg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold value of x: x* =  [2.99129226]\n"
     ]
    }
   ],
   "source": [
    "muhatarr = {}\n",
    "for i in range(len(X_train)):\n",
    "    muhatarr[i] = muhat(X_train[i])\n",
    "    #muhatarr[i][0] = X_train[i]\n",
    "sort_muhatarr = sorted(muhatarr.items(), key=lambda x: x[1], reverse=False)\n",
    "\n",
    "for i in range(len(muhatarr)):\n",
    "    if sort_muhatarr[i][1][0] >= 0.5:\n",
    "        thres_no = (sort_muhatarr[i][0])\n",
    "        #print(thres_no)\n",
    "        break\n",
    "        \n",
    "print('Threshold value of x: x* = ', X_train[thres_no])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      " [[80 20]\n",
      " [15 85]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "Y_test_pred=[]\n",
    "for x in X_test:\n",
    "    p1 = muhat(x)\n",
    "    if p1<0.5: \n",
    "        Y_test_pred.append(0)\n",
    "    else : \n",
    "        Y_test_pred.append(1)\n",
    "Y_test_pred = np.array(Y_test_pred)\n",
    "m = confusion_matrix(Y_test,Y_test_pred)\n",
    "print('Confusion matrix:\\n',m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean for positive data: mean_pos_hat =  [1.97611506]\n",
      "Mean for negative data: mean_neg_hat =  [4.01365675]\n",
      "Variance for positive data: var_pos_hat =  [0.97324824]\n",
      "Variance for negative data: var_neg_hat =  [1.02425662]\n",
      "Prior probability for Y=1: a_hat =  0.5\n",
      "Accuracy : 0.825\n"
     ]
    }
   ],
   "source": [
    "print('Mean for positive data: mean_pos_hat = ', mean_pos)\n",
    "print('Mean for negative data: mean_neg_hat = ', mean_neg)\n",
    "print('Variance for positive data: var_pos_hat = ', var_pos)\n",
    "print('Variance for negative data: var_neg_hat = ', var_neg)\n",
    "print('Prior probability for Y=1: a_hat = ', ahat)\n",
    "print('Accuracy : '+str((m[0][0]+m[1][1])/len(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From Discrete distribution of data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unlike the first exercise for learning the Naive Bayes' classifier where we dealt with continuous distribution of data, here you need to work with discrete data, which means finding Probability Mass Distribution(PMF). \n",
    "\n",
    "Age  | Income | Status  | Buy\n",
    "-----|--------|-------- |----\n",
    "<=20 |  low   | students| yes\n",
    "<=20 |  high  | students| yes\n",
    "<=20 | medium | students| no\n",
    "<=20 | medium | married | no\n",
    "<=20 |  high  | married | yes\n",
    "21-30|  low   | married | yes\n",
    "21-30|  low   | married | no \n",
    "21-30| medium | students| no\n",
    "21-30|  high  | students| yes\n",
    " >30 |  high  | married | no\n",
    " >30 |  high  | married | yes\n",
    " >30 | medium | married | yes\n",
    " >30 | medium | married | no\n",
    " >30 | medium | students| no\n",
    " \n",
    "Consider the train dataset above. Take any random datapoint ($X_{i}$) where $X_{i} = (X_{i,1} = Age,X_{i,2} = Income,X_{i,3} = Status)$ and its corresponding label \n",
    "\n",
    "($Y_{i} = Buy$). A \"yes\" in Buy corresponds to label-1 and a \"no\" in Buy corresponds to label-0.\n",
    "\n",
    "<br>**Instructions to follow for learning a Baeysian classifier:** *(Code the formulae for estimating the different parameters yourself)*\n",
    "<br> a)Estimate the prior probability: $P(Y=1)$  ⟶ which could be referred to as: $\\hat{a}$   \n",
    "b)Estimate the likelihood for each feature:  $P(X_{i,j} = x |Y = y_{i})$, where $ i$=datapoint counter, $j \\in \\{1,2,3\\}$ and $y_{i} \\in \\{0,1\\}$ \n",
    "<br>c)Estimate the total likelihood: $P(X_{i} = x |Y = y_{i})$  \n",
    "d)Calculate the posterior probability: $P(Y = 1|X_{i} = x_{test} )$ = $p_{test}$ where $x_{test} = (Age = 21-30, Income= medium, Status = married)$\n",
    "\n",
    "\n",
    "Return back: $\\hat{a}$, total likelihood and $p_{test}$ \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## write your code here.\n",
    "df = pd.read_csv('discretedata.txt',delimiter=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "for i in range(len(df.columns)):\n",
    "    le.fit(df[df.columns[i]])\n",
    "    df[df.columns[i]] = le.transform(df[df.columns[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Income</th>\n",
       "      <th>Status</th>\n",
       "      <th>Buy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Age  Income  Status  Buy\n",
       "0     1       1       1    1\n",
       "1     1       0       1    1\n",
       "2     1       2       1    0\n",
       "3     1       2       0    0\n",
       "4     1       0       0    1\n",
       "5     0       1       0    1\n",
       "6     0       1       0    0\n",
       "7     0       2       1    0\n",
       "8     0       0       1    1\n",
       "9     2       0       0    0\n",
       "10    2       0       0    1\n",
       "11    2       2       0    1\n",
       "12    2       2       0    0\n",
       "13    2       2       1    0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prior probability\n",
    "ones = 0\n",
    "for i in range(len(df['Buy'])):\n",
    "    if df['Buy'][i] == 1:\n",
    "        ones = ones + 1\n",
    "ahat = ones/len(df['Buy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(Xi,1 = <=20 | Y=1) =  0.42857142857142855\n",
      "P(Xi,1 = 21-30 | Y=1) =  0.2857142857142857\n",
      "P(Xi,1 = >30 | Y=1) =  0.2857142857142857\n",
      "P(Xi,1 = <=20 | Y=0) =  0.2857142857142857\n",
      "P(Xi,1 = 21-30 | Y=0) =  0.2857142857142857\n",
      "P(Xi,1 = >30 | Y=0) =  0.42857142857142855\n",
      "\n",
      "P(Xi,2 = low | Y=1) =  0.2857142857142857\n",
      "P(Xi,2 = high | Y=1) =  0.5714285714285714\n",
      "P(Xi,2 = medium | Y=1) =  0.14285714285714285\n",
      "P(Xi,2 = low | Y=0) =  0.14285714285714285\n",
      "P(Xi,2 = high | Y=0) =  0.14285714285714285\n",
      "P(Xi,2 = medium | Y=0) =  0.7142857142857143\n",
      "\n",
      "P(Xi,3 = student | Y=1) =  0.42857142857142855\n",
      "P(Xi,3 = married | Y=1) =  0.5714285714285714\n",
      "P(Xi,3 = student | Y=0) =  0.42857142857142855\n",
      "P(Xi,3 = married | Y=0) =  0.5714285714285714\n"
     ]
    }
   ],
   "source": [
    "#likelihood for each feature\n",
    "\n",
    "#Age\n",
    "#age1 age<=20\n",
    "#age0 age = 21-30\n",
    "#age2 age>30\n",
    "age = [0]*3\n",
    "for i in range(len(df['Age'])):\n",
    "    if df['Age'][i] == 0 and df['Buy'][i] == 1:\n",
    "        age[0] = age[0] + 1\n",
    "    if df['Age'][i] == 1 and df['Buy'][i] == 1:\n",
    "        age[1] = age[1] + 1\n",
    "    if df['Age'][i] == 2 and df['Buy'][i] == 1:\n",
    "        age[2] = age[2] + 1\n",
    "        \n",
    "print('P(Xi,1 = <=20 | Y=1) = ', (age[1]/len(df['Age']))/ahat)\n",
    "print('P(Xi,1 = 21-30 | Y=1) = ', (age[0]/len(df['Age']))/ahat)\n",
    "print('P(Xi,1 = >30 | Y=1) = ', (age[2]/len(df['Age']))/ahat)\n",
    "print('P(Xi,1 = <=20 | Y=0) = ', ((len(df[df['Age'] == 1])-age[1])/len(df['Age']))/(1-ahat))\n",
    "print('P(Xi,1 = 21-30 | Y=0) = ', ((len(df[df['Age'] == 0])-age[0])/len(df['Age']))/(1-ahat))\n",
    "print('P(Xi,1 = >30 | Y=0) = ', ((len(df[df['Age'] == 2])-age[2])/len(df['Age']))/(1-ahat))\n",
    "\n",
    "#Income\n",
    "#income1 low\n",
    "#income0 high\n",
    "#income2 medium\n",
    "income = [0]*3\n",
    "for i in range(len(df['Income'])):\n",
    "    if df['Income'][i] == 0 and df['Buy'][i] == 1:\n",
    "        income[0] = income[0] + 1\n",
    "    if df['Income'][i] == 1 and df['Buy'][i] == 1:\n",
    "        income[1] = income[1] + 1\n",
    "    if df['Income'][i] == 2 and df['Buy'][i] == 1:\n",
    "        income[2] = income[2] + 1\n",
    "        \n",
    "print('\\nP(Xi,2 = low | Y=1) = ', (income[1]/len(df['Income'])/ahat))\n",
    "print('P(Xi,2 = high | Y=1) = ', (income[0]/len(df['Income'])/ahat))\n",
    "print('P(Xi,2 = medium | Y=1) = ', (income[2]/len(df['Income'])/ahat))\n",
    "print('P(Xi,2 = low | Y=0) = ', ((len(df[df['Income'] == 1])-income[1])/len(df['Income']))/(1-ahat))\n",
    "print('P(Xi,2 = high | Y=0) = ', ((len(df[df['Income'] == 0])-income[0])/len(df['Income']))/(1-ahat))\n",
    "print('P(Xi,2 = medium | Y=0) = ', ((len(df[df['Income'] == 2])-income[2])/len(df['Income']))/(1-ahat))\n",
    "        \n",
    "#Status\n",
    "#status1 student\n",
    "#status0 married\n",
    "status = [0]*2\n",
    "for i in range(len(df['Status'])):\n",
    "    if df['Status'][i] == 0 and df['Buy'][i] == 1:\n",
    "        status[0] = status[0] + 1\n",
    "    if df['Status'][i] == 1 and df['Buy'][i] == 1:\n",
    "        status[1] = status[1] + 1\n",
    "print('\\nP(Xi,3 = student | Y=1) = ', (status[1]/len(df['Status'])/ahat))\n",
    "print('P(Xi,3 = married | Y=1) = ', (status[0]/len(df['Status'])/ahat))\n",
    "print('P(Xi,3 = student | Y=0) = ', ((len(df[df['Status'] == 1])-status[1])/len(df['Status']))/(1-ahat))\n",
    "print('P(Xi,3 = married | Y=0) = ', ((len(df[df['Status'] == 0])-status[0])/len(df['Status']))/(1-ahat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(age = 0 , income = 0 , status = 0 | Y=1): 0.023323615160349854\n",
      "P(age = 0 , income = 0 , status = 0 | Y=0): 0.0058309037900874635\n",
      "P(age = 0 , income = 0 , status = 1 | Y=1): 0.01749271137026239\n",
      "P(age = 0 , income = 0 , status = 1 | Y=0): 0.004373177842565598\n",
      "P(age = 0 , income = 1 , status = 0 | Y=1): 0.011661807580174927\n",
      "P(age = 0 , income = 1 , status = 0 | Y=0): 0.0058309037900874635\n",
      "P(age = 0 , income = 1 , status = 1 | Y=1): 0.008746355685131196\n",
      "P(age = 0 , income = 1 , status = 1 | Y=0): 0.004373177842565598\n",
      "P(age = 0 , income = 2 , status = 0 | Y=1): 0.0058309037900874635\n",
      "P(age = 0 , income = 2 , status = 0 | Y=0): 0.029154518950437316\n",
      "P(age = 0 , income = 2 , status = 1 | Y=1): 0.004373177842565598\n",
      "P(age = 0 , income = 2 , status = 1 | Y=0): 0.021865889212827987\n",
      "P(age = 1 , income = 0 , status = 0 | Y=1): 0.03498542274052478\n",
      "P(age = 1 , income = 0 , status = 0 | Y=0): 0.0058309037900874635\n",
      "P(age = 1 , income = 0 , status = 1 | Y=1): 0.026239067055393587\n",
      "P(age = 1 , income = 0 , status = 1 | Y=0): 0.004373177842565598\n",
      "P(age = 1 , income = 1 , status = 0 | Y=1): 0.01749271137026239\n",
      "P(age = 1 , income = 1 , status = 0 | Y=0): 0.0058309037900874635\n",
      "P(age = 1 , income = 1 , status = 1 | Y=1): 0.013119533527696793\n",
      "P(age = 1 , income = 1 , status = 1 | Y=0): 0.004373177842565598\n",
      "P(age = 1 , income = 2 , status = 0 | Y=1): 0.008746355685131196\n",
      "P(age = 1 , income = 2 , status = 0 | Y=0): 0.029154518950437316\n",
      "P(age = 1 , income = 2 , status = 1 | Y=1): 0.006559766763848397\n",
      "P(age = 1 , income = 2 , status = 1 | Y=0): 0.021865889212827987\n",
      "P(age = 2 , income = 0 , status = 0 | Y=1): 0.023323615160349854\n",
      "P(age = 2 , income = 0 , status = 0 | Y=0): 0.008746355685131196\n",
      "P(age = 2 , income = 0 , status = 1 | Y=1): 0.01749271137026239\n",
      "P(age = 2 , income = 0 , status = 1 | Y=0): 0.006559766763848397\n",
      "P(age = 2 , income = 1 , status = 0 | Y=1): 0.011661807580174927\n",
      "P(age = 2 , income = 1 , status = 0 | Y=0): 0.008746355685131196\n",
      "P(age = 2 , income = 1 , status = 1 | Y=1): 0.008746355685131196\n",
      "P(age = 2 , income = 1 , status = 1 | Y=0): 0.006559766763848397\n",
      "P(age = 2 , income = 2 , status = 0 | Y=1): 0.0058309037900874635\n",
      "P(age = 2 , income = 2 , status = 0 | Y=0): 0.043731778425655975\n",
      "P(age = 2 , income = 2 , status = 1 | Y=1): 0.004373177842565598\n",
      "P(age = 2 , income = 2 , status = 1 | Y=0): 0.03279883381924198\n"
     ]
    }
   ],
   "source": [
    "#total likelihood\n",
    "for i in range(len(age)):\n",
    "    for j in range(len(income)):\n",
    "        for k in range(len(status)):\n",
    "            prob_1 = (age[i]*income[j]*status[k])/(((len(df['Age']))**3)*ahat)\n",
    "            prob_0 = ((len(df[df['Age'] == i]) - age[i])*(len(df[df['Income'] == j]) - income[j])*(len(df[df['Status'] == k]) - status[k]))/(((len(df['Age']))**3)*(1-ahat))\n",
    "            print('P(age =',i,', income =', j,', status =', k,'| Y=1):', prob_1)\n",
    "            print('P(age =',i,', income =', j,', status =', k,'| Y=0):', prob_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P_test for the given x_test is = 0.16666666666666663\n",
      "Required a_hat= 0.5\n"
     ]
    }
   ],
   "source": [
    "#posterior probability\n",
    "\n",
    "#𝑥𝑡𝑒𝑠𝑡=(𝐴𝑔𝑒=21−30,𝐼𝑛𝑐𝑜𝑚𝑒=𝑚𝑒𝑑𝑖𝑢𝑚,𝑆𝑡𝑎𝑡𝑢𝑠=𝑚𝑎𝑟𝑟𝑖𝑒𝑑)\n",
    "#age = 0, income = 2, status = 0\n",
    "age0=0\n",
    "income2=0\n",
    "status0=0\n",
    "for i in range(len(df['Age'])):\n",
    "    if df['Age'][i] == 0: \n",
    "        age0 = age0 + 1\n",
    "    if df['Income'][i] == 2:\n",
    "        income2 = income2 + 1\n",
    "    if df['Status'][i] == 0:\n",
    "        status0 = status0 + 1\n",
    "        \n",
    "num = ((age[0]/len(df['Age']))/ahat)*((income[2]/len(df['Income']))/ahat)*((status[0]/len(df['Status']))/ahat)*ahat\n",
    "den = (age0*income2*status0)/((len(df['Age']))**3)\n",
    "\n",
    "p_test = num/den\n",
    "print('P_test for the given x_test is =', p_test)\n",
    "print('Required a_hat=', ahat)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
